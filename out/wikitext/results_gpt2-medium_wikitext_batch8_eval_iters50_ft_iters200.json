{"config": {"DEBUG": false, "master_process": true, "out_dir": "out/wikitext", "eval_interval": 10, "log_interval": 10, "eval_iters": 50, "eval_only": false, "always_save_checkpoint": false, "init_from": "gpt2-medium", "wandb_log": true, "wandb_project": "wikitext", "wandb_run_name": "gpt2-medium_wikitext_batch8_eval_iters50_ft_iters200-1702832812.7761054", "dataset": "wikitext", "gradient_accumulation_steps": 40, "batch_size": 8, "block_size": 1024, "n_layer": 12, "n_head": 12, "n_embd": 768, "dropout": 0.1, "bias": false, "learning_rate": 0.0006, "max_iters": 200, "weight_decay": 0.1, "beta1": 0.9, "beta2": 0.95, "grad_clip": 1.0, "decay_lr": true, "warmup_iters": 2000, "lr_decay_iters": 600000, "min_lr": 6e-05, "backend": "nccl", "device": "cuda", "dtype": "bfloat16", "compile": false}, "tokens_per_iter": 327680, "losses": {"0": {"train": 4.033341884613037, "val": 4.038511276245117}, "10": {"train": 4.009945869445801, "val": 3.995105266571045}, "50": {"train": 3.8022620677948, "val": 3.8113043308258057}, "100": {"train": 3.674119472503662, "val": 3.685506582260132}}, "best_val_loss": 3.5561232566833496, "average_time_per_iter": 17.406479040384294, "max_memory_per_gpu": 15573759508.48}